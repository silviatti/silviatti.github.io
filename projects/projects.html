---
layout: single
author_profile: true
title: "My Projects"

header: 
       overlay_image: "assets/template_2.png"
       overlay_filter: 0.0
---

My research focuses on the area of Topic Modeling and Natural Language Processing. 
My interests span multiple areas across NLP and machine learning, including Sentiment Analysis, Hate Speech, Word Representation, and Deep Learning.  
</br>
</br>
Here a selected collections of some projects I've been working on.


<h2 id="CRTM"><b>Constrained Relational Topic Models</b></h2>
Topics models can automatically extract topics from collections of documents.
If two documents are related to each other (e.g. citations) are more likely to talk about similar topics. 
I designed and developed a semi-supervised topic model that jointly models the relationships of a network of documents and 
some prior knowledge related to documents in the form of constraints. This work has been accepted on an international journal! 
My very first paper! Check it out: 
    [<a href="https://github.com/MIND-Lab/Constrained-RTM">Code</a>] [<a href="https://doi.org/10.1016/j.ins.2019.09.039">Paper</a>]


<h2 id="NTM"><b>Contextualized Neural Topic Models</b></h2>
Recently, neural topic models have become available. Concurrently, BERT-based representations have advanced the state of the art of neural models.
In collaboration with <a href="https://github.com/MilaNLProc">MilaNLP lab</a> @ Bocconi University, we combined pre-trained BERT representations and neural topic models. 
BERT sentence embeddings indeed generate more meaningful and coherent topics than bag of word approaches in either standard LDA or existing neural topic models.
This also allowed us to address the problem of zero-shot cross-lingual topic modeling.  
</br>
Check it out the preprints: [<a href="https://arxiv.org/abs/2004.03974">Arxiv:2004.03974</a>] [<a href="https://arxiv.org/abs/2004.07737">Arxiv:2004.07737</a>]
</br>
And here's the python library that reached over 10k downloads!  [<a href="https://pypi.org/project/contextualized-topic-models/">contextualized-topic-models</a>]

<h2 id="bo4tm">Hyperparameter Optimization for Topic Models</h2> Hyperpameters that regulate the random variables of topic models can have a strong impact on 
the overall performance of a model. I am empirically studying the impact of the hyperparameters of a subset of topics models. I'm investigating this problem 
by applying Bayesian optimization techniques to identify the best configuration of hyperparameters for a topic model applied in a classification task. 
</br> Related to this problem, I aim to extend this work and study the impact of hyperparameters on a wider set of topic models. I am actually planning to implement a 
comparative evaluation framework in which we can compare optimized topic models and investigate multiple performance metrics. 


<h2 id="ecrtm">Topic Models in Relational Environments </h2> Multiple types of relational information can be incorporated into topic models.
I am studying how document-level relationships and word-level relationships affect the results of a topic model. 
As for the word-level relationships, I am considering relationships between the named-entities identified in a document. The idea is that two named-entities are more 
likely to share the same topics, rather than two single tokens (that may be ambiguous considered as single words). [<a href="https://github.com/MIND-Lab/EC-RTM">Code</a>] 
